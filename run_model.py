import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
import time
from playsound import playsound
import threading

class DrowsinessDetector:
    def __init__(self, model_path='my_model.h5'):
        """
        Kh·ªüi t·∫°o detector bu·ªìn ng·ªß
        
        Args:
            model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file model .h5
        """
        print("üîÑ ƒêang t·∫£i model...")
        self.model = keras.models.load_model(model_path)
        print("‚úì Model ƒë√£ s·∫µn s√†ng!")
        
        # K√≠ch th∆∞·ªõc input c·ªßa model
        self.img_size = (145, 145)
        
        # Load face detector t·ª´ OpenCV
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        
        # Load eye detector (ƒë·ªÉ ph√°t hi·ªán m·∫Øt)
        self.eye_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_eye.xml'
        )
        
        # Ng∆∞·ª°ng c·∫£nh b√°o
        self.drowsy_threshold = 0.5  # N·∫øu > 0.5 = bu·ªìn ng·ªß
        self.alert_frames = 0  # ƒê·∫øm s·ªë frame li√™n ti·∫øp bu·ªìn ng·ªß
        self.alert_limit = 15  # C·∫£nh b√°o sau 15 frame li√™n ti·∫øp
        
        # Tr·∫°ng th√°i
        self.is_playing_alert = False
        
    def preprocess_face(self, face_img):
        """
        Ti·ªÅn x·ª≠ l√Ω ·∫£nh khu√¥n m·∫∑t
        
        Args:
            face_img: ·∫¢nh khu√¥n m·∫∑t t·ª´ webcam
            
        Returns:
            ·∫¢nh ƒë√£ x·ª≠ l√Ω s·∫µn s√†ng cho model
        """
        # Resize v·ªÅ k√≠ch th∆∞·ªõc model y√™u c·∫ßu
        face_resized = cv2.resize(face_img, self.img_size)
        
        # Chu·∫©n h√≥a pixel v·ªÅ [0, 1]
        face_normalized = face_resized.astype('float32') / 255.0
        
        # Th√™m batch dimension
        face_batch = np.expand_dims(face_normalized, axis=0)
        
        return face_batch
    
    def predict_drowsiness(self, face_img):
        """
        D·ª± ƒëo√°n tr·∫°ng th√°i bu·ªìn ng·ªß
        
        Args:
            face_img: ·∫¢nh khu√¥n m·∫∑t
            
        Returns:
            prediction: Gi√° tr·ªã d·ª± ƒëo√°n (0-1)
            status: Tr·∫°ng th√°i ("T·ªânh t√°o" ho·∫∑c "Bu·ªìn ng·ªß")
        """
        # Ti·ªÅn x·ª≠ l√Ω
        processed_face = self.preprocess_face(face_img)
        
        # D·ª± ƒëo√°n
        prediction = self.model.predict(processed_face, verbose=0)[0][0]
        
        # X√°c ƒë·ªãnh tr·∫°ng th√°i
        if prediction > self.drowsy_threshold:
            status = "Bu·ªìn ng·ªß"
            color = (0, 0, 255)  # ƒê·ªè
        else:
            status = "T·ªânh t√°o"
            color = (0, 255, 0)  # Xanh l√°
            
        return prediction, status, color
    
    def play_alert_sound(self):
        """Ph√°t √¢m thanh c·∫£nh b√°o"""
        if not self.is_playing_alert:
            self.is_playing_alert = True
            # T·∫°o beep sound b·∫±ng OpenCV
            print("\nüö® C·∫¢NH B√ÅO: BU·ªíN NG·ª¶! üö®")
            # B·∫°n c√≥ th·ªÉ th√™m file √¢m thanh:
            # threading.Thread(target=lambda: playsound('alert.mp3')).start()
            time.sleep(0.5)
            self.is_playing_alert = False
    
    def draw_info(self, frame, face_rect, prediction, status, color, fps):
        """
        V·∫Ω th√¥ng tin l√™n frame
        
        Args:
            frame: Frame video
            face_rect: T·ªça ƒë·ªô khu√¥n m·∫∑t (x, y, w, h)
            prediction: Gi√° tr·ªã d·ª± ƒëo√°n
            status: Tr·∫°ng th√°i
            color: M√†u s·∫Øc
            fps: Frames per second
        """
        x, y, w, h = face_rect
        
        # V·∫Ω khung quanh khu√¥n m·∫∑t
        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)
        
        # T·∫°o background cho text
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (400, 180), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
        
        # Hi·ªÉn th·ªã th√¥ng tin
        cv2.putText(frame, f"Tr·∫°ng th√°i: {status}", (20, 40),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        cv2.putText(frame, f"ƒê·ªô bu·ªìn ng·ªß: {prediction:.2%}", (20, 75),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame, f"FPS: {fps:.1f}", (20, 110),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # Thanh progress bar
        bar_width = int(prediction * 350)
        cv2.rectangle(frame, (20, 130), (370, 160), (50, 50, 50), -1)
        cv2.rectangle(frame, (20, 130), (20 + bar_width, 160), color, -1)
        
        # C·∫£nh b√°o n·∫øu bu·ªìn ng·ªß
        if status == "Bu·ªìn ng·ªß":
            cv2.putText(frame, "‚ö†Ô∏è C·∫¢NH B√ÅO! ‚ö†Ô∏è", (x-20, y-20),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)
        
        return frame
    
    def run(self):
        """Ch·∫°y ·ª©ng d·ª•ng ph√°t hi·ªán bu·ªìn ng·ªß"""
        print("\n" + "="*60)
        print("üé• PH√ÅT HI·ªÜN BU·ªíN NG·ª¶ QUA WEBCAM")
        print("="*60)
        print("üìå H∆∞·ªõng d·∫´n:")
        print("  - Nh√¨n th·∫≥ng v√†o camera")
        print("  - Nh·∫•n 'q' ƒë·ªÉ tho√°t")
        print("  - Nh·∫•n 's' ƒë·ªÉ ch·ª•p ·∫£nh")
        print("="*60 + "\n")
        
        # M·ªü webcam
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            print("‚ùå Kh√¥ng th·ªÉ m·ªü webcam!")
            return
        
        # ƒê·∫∑t ƒë·ªô ph√¢n gi·∫£i
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        # FPS counter
        fps_start_time = time.time()
        fps_counter = 0
        fps = 0
        
        while True:
            ret, frame = cap.read()
            
            if not ret:
                print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ webcam!")
                break
            
            # L·∫≠t frame ƒë·ªÉ hi·ªÉn th·ªã nh∆∞ g∆∞∆°ng
            frame = cv2.flip(frame, 1)
            
            # Chuy·ªÉn sang grayscale ƒë·ªÉ detect face
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # Ph√°t hi·ªán khu√¥n m·∫∑t
            faces = self.face_cascade.detectMultiScale(
                gray, 
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(100, 100)
            )
            
            if len(faces) > 0:
                # L·∫•y khu√¥n m·∫∑t l·ªõn nh·∫•t
                face = max(faces, key=lambda rect: rect[2] * rect[3])
                x, y, w, h = face
                
                # C·∫Øt khu√¥n m·∫∑t
                face_img = frame[y:y+h, x:x+w]
                
                # D·ª± ƒëo√°n
                prediction, status, color = self.predict_drowsiness(face_img)
                
                # ƒê·∫øm s·ªë frame bu·ªìn ng·ªß li√™n ti·∫øp
                if status == "Bu·ªìn ng·ªß":
                    self.alert_frames += 1
                    if self.alert_frames >= self.alert_limit:
                        self.play_alert_sound()
                else:
                    self.alert_frames = 0
                
                # V·∫Ω th√¥ng tin
                frame = self.draw_info(frame, face, prediction, status, color, fps)
                
            else:
                # Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t
                cv2.putText(frame, "Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t", (20, 40),
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            
            # T√≠nh FPS
            fps_counter += 1
            if fps_counter >= 10:
                fps = fps_counter / (time.time() - fps_start_time)
                fps_counter = 0
                fps_start_time = time.time()
            
            # Hi·ªÉn th·ªã frame
            cv2.imshow('Ph√°t hi·ªán bu·ªìn ng·ªß - Nh·∫•n Q ƒë·ªÉ tho√°t', frame)
            
            # X·ª≠ l√Ω ph√≠m
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("\nüëã ƒêang tho√°t...")
                break
            elif key == ord('s'):
                # Ch·ª•p ·∫£nh
                filename = f"screenshot_{int(time.time())}.jpg"
                cv2.imwrite(filename, frame)
                print(f"üì∏ ƒê√£ l∆∞u ·∫£nh: {filename}")
        
        # D·ªçn d·∫πp
        cap.release()
        cv2.destroyAllWindows()
        print("‚úì ƒê√£ ƒë√≥ng webcam")


# ============================
# CH·∫†Y CH∆Ø∆†NG TR√åNH
# ============================

if __name__ == "__main__":
    # Kh·ªüi t·∫°o detector
    detector = DrowsinessDetector(model_path='my_model.h5')
    
    # Ch·∫°y
    detector.run()